# MLOps Project: Pairwise Binary Classification

Проект для обучения модели бинарной классификации пар товаров на основе текстовых и визуальных эмбеддингов.

## Описание проекта

Проект решает задачу определения, являются ли два товара одинаковыми или разными на основе их текстовых описаний и изображений. Модель использует предобученные эмбеддинги:
- Текстовые эмбеддинги: BERT (64-мерные векторы)
- Визуальные эмбеддинги: ResNet (128-мерные векторы)

Архитектура модели представляет собой нейронную сеть с несколькими полносвязными слоями, которая принимает на вход конкатенированные эмбеддинги двух товаров и выдает вероятность того, что они являются одним и тем же товаром.

## Технические детали

### Структура проекта

```
mlops/
├── config/              # Hydra конфигурации
│   ├── config.yaml      # Главный конфиг
│   ├── data/            # Конфиги данных
│   ├── model/           # Конфиги модели
│   ├── optimizer/       # Конфиги оптимизатора
│   └── trainer/         # Конфиги тренировки
├── matching/            # Основной код проекта
│   ├── __init__.py
│   ├── dataset.py       # Dataset класс
│   ├── model.py         # Модель PairwiseBinaryClassifier
│   ├── train.py         # Скрипт тренировки
│   ├── infer.py         # Скрипт инференса
│   └── utils.py         # Утилиты
├── data/                # Данные (управляются через DVC)
├── main.py              # Точка входа для тренировки
├── pyproject.toml       # Зависимости (Poetry)
├── .pre-commit-config.yaml  # Конфигурация pre-commit
└── README.md            # Этот файл
```

## Setup

### Требования

- Python 3.9+
- Poetry

### Установка окружения

1. **Клонируйте репозиторий:**
   ```bash
   git clone <repository-url>
   cd mlops
   ```

2. **Создайте виртуальное окружение и установите зависимости:**
   ```bash
   pip install poetry
   
   poetry install
   
   poetry shell
   ```

3. **Установите pre-commit хуки:**
   ```bash
   pre-commit install
   ```

4. **Проверьте, что все хуки работают:**
   ```bash
   pre-commit run -a
   ```

5. **Подготовьте данные:**
   
   Данные должны быть скачаны с Яндекс Диска: https://disk.yandex.ru/d/bSNKwDpGHTTvAg
   
   После скачивания архива `competition.zip`, распакуйте его в папку `data/`:
   ```bash
   # Создайте папку data, если её нет
   mkdir -p data
   
   # Распакуйте архив (замените путь на ваш)
   unzip competition.zip -d data/
   ```
   
   Структура папки `data/` должна быть следующей:
   ```
   data/
   ├── images_embed.parquet
   ├── text_and_bert.parquet
   └── train.parquet
   ```

## Train

### Запуск тренировки

Для запуска тренировки модели используйте:

```bash
# Через main.py
python main.py

```

Используется Hydra для управления конфигурацией.


### Что происходит во время тренировки

1. **Загрузка данных:** Данные загружаются из parquet файлов, эмбеддинги нормализуются
2. **Разделение на train/test:** Данные разделяются в соотношении 80/20
3. **Создание датасетов:** Создаются PyTorch Dataset и DataLoader объекты
4. **Инициализация модели:** Создается модель согласно конфигурации
5. **Тренировка:** Модель обучается на указанное количество эпох
6. **Логирование:** Все метрики логируются в MLflow:
   - Loss на каждой эпохе (train и validation)
   - Финальные метрики: Accuracy, Precision, Recall, F1, PR-AUC
   - Графики: кривые loss, precision-recall curve, bar chart метрик
   - Гиперпараметры и git commit id
7. **Сохранение модели:** Обученная модель сохраняется в `pairwise_binary_classifier.pth`


## Конфигурация

Все гиперпараметры настраиваются через Hydra конфиги в папке `config/`:

- `config/data/data.yaml` - пути к данным, размер тестовой выборки
- `config/model/model.yaml` - архитектура модели (размеры эмбеддингов, hidden size, количество слоев)
- `config/optimizer/adam.yaml` - параметры оптимизатора (learning rate)
- `config/trainer/trainer.yaml` - параметры тренировки (batch size, количество эпох)
- `config/config.yaml` - главный конфиг, объединяющий все остальные, настройки MLflow и DVC

## Зависимости

Все зависимости управляются через Poetry и указаны в `pyproject.toml`. Основные библиотеки:

- `torch` - PyTorch для обучения модели
- `pandas`, `numpy` - работа с данными
- `scikit-learn` - метрики и разделение данных
- `hydra-core` - управление конфигурацией
- `mlflow` - логирование экспериментов
- `dvc` - управление версиями данных

## Скрины запуска
- Скрин запуска тренировки на искусственном дата-сете, у меня на ноуте гпу нет(
![Снимок экрана 2025-12-30 195603](https://github.com/user-attachments/assets/93f01766-fe01-4297-bf89-a13377eb63b8)
- скрин с структурой репозитория после запуска тренировки, где видно сохранение гидры, метрик, рисунков и модели
![Снимок экрана 2025-12-30 195735](https://github.com/user-attachments/assets/6dc34c23-fd25-46a0-b65a-2f274095957d)


